This project uses an evolutionary strategy algorithm to train a deep neural network to play a simple version of the dinosaur game. It is intended to be a proof of concept for the algorithm. The game is implemented with pygame and the evolutionary strategy implementation is based off of _Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari_ [https://arxiv.org/pdf/1802.08842]. It uses tensorflow to run the model, which consists of 2 input neurons, (distance to cactus, speed) and a discrete output (jump). The algorithm running with a population of 10 can evolve an agent that achieves a score of 134 after 5 generations.
<img src="https://github.com/PaulBailey-1/ES-dino/assets/64763623/893f6cc7-9573-4f39-a26a-bb1e25705847" width="800">
